{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1edfc8-c469-4315-a0c7-5874d77d968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955c2e7d-f1c0-415d-8c42-e691f72d9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid params\n",
    "GRID_SIZE = 4\n",
    "TERMINAL_STATE = (3,3)\n",
    "START_STATE = (0,0)\n",
    "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "ACTION_MAP = {\n",
    "    'UP' : (-1,0),\n",
    "    'DOWN' : (1,0),                 #Les index qui se déplacent en gardant soit la même ligne soit la même colonne\n",
    "    'LEFT' : (0,-1),\n",
    "    'RIGHT' : (0,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52ad529-1a39-4edd-b9c8-61a74516e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld : \n",
    "    def __init__(self, size, start, terminal) :\n",
    "        self.size = size\n",
    "        self.start = start\n",
    "        self.terminal = terminal\n",
    "        self.state = start\n",
    "\n",
    "    def reset(self) : \n",
    "        self.state = self.start\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action) : \n",
    "        if self.state == self.terminal : \n",
    "            return self.state, 0, True  #Reward = 0\n",
    "\n",
    "        #Compute the next step\n",
    "        delta = ACTION_MAP[action]\n",
    "        next_state = (self.state[0] + delta[0], self.state[1] + delta[1])\n",
    "\n",
    "        #keep the agent within limits\n",
    "        next_state = (\n",
    "            max(0, min(self.state[0], self.size-1)),\n",
    "            max(0, min(self.state[1], self.size-1))\n",
    "        )\n",
    "\n",
    "        #Reward = -1 for each other step\n",
    "        reward = -1\n",
    "        done = self.state == self.terminal\n",
    "        self.state = next_state\n",
    "        return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c4d94c5-7806-43c9-a095-ecdc259707ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarlo : \n",
    "    def __init__(self, env, gamma = 0.99) : \n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.state_values = defaultdict(float)\n",
    "        self.visit_counts = defaultdict(int)\n",
    "\n",
    "    def generate_episode(self) : \n",
    "        #generate episode with a random policy\n",
    "        episode = []\n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done : \n",
    "            action = random.choice(ACTIONS) #random policy\n",
    "            next_state, reward, done = self.env.step(action)\n",
    "            episode.append((state, action, reward))\n",
    "            state = next_state\n",
    "\n",
    "        return episode\n",
    "\n",
    "    def update_values(self, episode) :\n",
    "        #Monte carlo method for updating value\n",
    "        G = 0\n",
    "        visited_states = set()\n",
    "\n",
    "        for t in reversed(range(len(episode))) : \n",
    "            state, _, reward = episode[t]\n",
    "            G = reward + self.gamma*G #return function\n",
    "            \n",
    "            if state not in visited_states :\n",
    "                self.visit_counts[state] += 1\n",
    "                self.state_values[state] += (G - self.state_values[state]/self.visit_counts[state])\n",
    "                visited_state.add(state)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1701d0a8-ef90-4020-8c4c-ddb1f5ba4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorld(size=GRID_SIZE, start=START_STATE, terminal=TERMINAL_STATE)\n",
    "agent = MonteCarlo(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f4514-c228-4e55-8e1b-4d7e66ac3c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 100\n",
    "for episode in range(num_episodes):\n",
    "    episode_data = agent.generate_episode()\n",
    "    agent.update_values(episode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5da406-db85-4742-bc7f-324e8a2c4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Values states :\")\n",
    "for i in range(GRID_SIZE):\n",
    "    for j in range(GRID_SIZE):\n",
    "        print(f\"{(i, j)}: {agent.state_values[(i, j)]:.2f}\", end=\"  \")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
